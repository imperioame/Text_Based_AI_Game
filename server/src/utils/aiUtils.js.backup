const { HfInference } = require('@huggingface/inference');
const fs = require('fs');
const path = require('path');

const hf = new HfInference(process.env.HUGGINGFACE_API_KEY);

const conversationHistory = [];
const logFilePath = path.join(__dirname, 'interaction_log.txt');

const storyThemes = [
  "space exploration",
  "medieval fantasy",
  "cyberpunk dystopia",
  "underwater civilization",
  "post-apocalyptic wasteland",
  "steampunk adventure",
  "ancient Egyptian mystery",
  "wild west frontier",
  "arctic expedition",
  "jungle survival",
  "random"
];

const EOP = "<EOP>"; // End Of Prompt
const WFP = "<WFP>"; // Wait For Prompt

function logInteraction(type, message) {
  const logEntry = `[${new Date().toISOString()}] ${type}: ${message}\n`;
  fs.appendFileSync(logFilePath, logEntry);
  console.log(logEntry);
}

async function initializeAI() {
  const initPrompt = `You will receive prompts in parts. When you see "${WFP}", wait for the next part. Respond only after you see "${EOP}".`;

  logInteraction('System', initPrompt);

  const response = await hf.textGeneration({
    model: 'facebook/blenderbot-400M-distill',
    inputs: initPrompt,
    parameters: {
      max_new_tokens: 50,
      temperature: 0.8,
      top_p: 0.9,
    },
  });

  logInteraction('AI', response.generated_text.trim());
}

exports.generateStory = async () => {
  await initializeAI();
  const randomTheme = storyThemes[Math.floor(Math.random() * storyThemes.length)];
  const prompt =`Tell me a story in ${randomTheme}. I'm the main character. What do I see, what's the current situation. Tell me what can i do.`;
  /*const prompt = `Generate a text-based adventure game opening scenario for a ${randomTheme} theme. Follow this structure:
1. Setting: Describe the initial setting in 2-3 sentences.
2. Character: Introduce the main character in 1-2 sentences.
3. Situation: Explain the current situation or challenge in 2-3 sentences.
4. Options: Provide exactly three numbered options for the player, each on a new line.`;
*/
  logInteraction('User', prompt);

  const serializedPrompts = serializePrompt(prompt);

  let fullResponse = '';
  for (const chunk of serializedPrompts) {
    logInteraction('User Chunk', chunk);

    const response = await hf.textGeneration({
      model: 'facebook/blenderbot-400M-distill',
      inputs: chunk,
      parameters: {
        max_new_tokens: 250,
        temperature: 0.8,
        top_p: 0.9,
      },
    });

    const chunkResponse = response.generated_text.trim();
    logInteraction('AI Chunk', chunkResponse);
    fullResponse += chunkResponse + ' ';
  }

  const story = fullResponse.replace(EOP, '').replace(WFP, '').trim();
  conversationHistory.push(story);

  logInteraction('AI', story);

  const { processedStory, options } = extractStoryAndOptions(story);
  const gameState = { scene: 'opening', theme: randomTheme, lastScene: processedStory };

  return { story: processedStory, options, gameState };
};

exports.getConversationHistory = () => {
  return conversationHistory;
};

exports.processAction = async (gameState, action) => {
  const prompt =`I ${action}. What happens next? Remember that this is a ${gameState.theme} story`
  /*const prompt = `Continue the ${gameState.theme} adventure. Last: ${gameState.lastScene}. Action: ${action}. Follow with:
1. Outcome: Result of the action in 2-3 sentences.
2. New Situation: New situation or challenge in 2-3 sentences.
3. Options: Three numbered options for the player.`;
*/

  logInteraction('System', gameState.lastScene);
  logInteraction('User', prompt);

  const serializedPrompts = serializePrompt(prompt);

  let fullResponse = '';
  for (const chunk of serializedPrompts) {
    logInteraction('User Chunk', chunk);

    const response = await hf.textGeneration({
      model: 'facebook/blenderbot-400M-distill',
      inputs: chunk,
      parameters: {
        max_new_tokens: 250,
        temperature: 0.8,
        top_p: 0.9,
      },
    });

    const chunkResponse = response.generated_text.trim();
    logInteraction('AI Chunk', chunkResponse);
    fullResponse += chunkResponse + ' ';
  }

  const story = fullResponse.replace(EOP, '').replace(WFP, '').trim();
  conversationHistory.push(story);

  logInteraction('AI', story);

  const { processedStory, options } = extractStoryAndOptions(story);
  const newGameState = { ...gameState, scene: 'continuation', lastScene: processedStory };

  return { story: processedStory, options, gameState: newGameState };
};

function extractStoryAndOptions(text) {
  const parts = text.split(/\n(?=\d+\.)/);
  let processedStory = parts[0].trim();
  let options = [];

  if (parts.length > 1) {
    options = parts.slice(1).map(part => part.trim());
  }

  // If we don't have exactly 3 options, generate some based on the story
  if (options.length !== 3) {
    const genericOptions = [
      "Investigate further",
      "Talk to someone nearby",
      "Check your surroundings",
      "Use an item from your inventory",
      "Rest and plan your next move",
      "Try to find a way out",
      "Search for clues",
      "Attempt to use a skill or ability",
      "Call for help",
      "Set up camp or find shelter"
    ];

    while (options.length < 3) {
      const newOption = genericOptions[Math.floor(Math.random() * genericOptions.length)];
      if (!options.includes(newOption)) {
        options.push(`${options.length + 1}. ${newOption}`);
      }
    }

    // Append the generated options to the story
    processedStory += "\n\nYour options are:";
    options.forEach(option => {
      processedStory += `\n${option}`;
    });
  }

  // Separate the last scene narrative from the options for optimization
  const narrative = processedStory.split("\n\nYour options are:")[0].trim();

  logInteraction('System', processedStory);  
  logInteraction('System', options);  
  logInteraction('System', narrative);  
  return { processedStory, options, narrative };
}

function serializePrompt(prompt, chunkSize = 250) {
  const chunks = [];
  let currentChunk = '';

  const addChunk = (text) => {
    if (currentChunk.length + text.length > chunkSize) {
      chunks.push(currentChunk.trim());
      currentChunk = WFP + ' ';
    }
    currentChunk += text;
  };

  const parts = prompt.split(/\s+/);
  for (const part of parts) {
    addChunk(part + ' ');
  }
  if (currentChunk) {
    chunks.push(currentChunk.trim() + ' ' + EOP);
  } else {
    chunks[chunks.length - 1] += ' ' + EOP;
  }

  return chunks;
}
